# mediapipe_llminference_example
This Flutter Example enables seamless integration with custom LLM (Large Language Model) inference via platform channels, allowing developers to initialize models, generate synchronous or asynchronous responses, and process results dynamically.
